{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#워닝 메시지\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Dataset/Undersampling/OSS_0.33_train.csv', encoding='euc-kr')\n",
    "test = pd.read_csv('./Dataset/Undersampling/OSS_0.33_test.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_int=train[['총자산대비잉여현금흐름', 'log자산총계', '순운전자본회전률', '총자본증가율', '자기자본구성비율', '총자본회전률',\n",
    "       '자기자본회전률', '자기자본증가율', '유동자산회전률', '총자산대비현금흐름', '총자본투자효율', '총자본순이익률']]\n",
    "\n",
    "X_test_int=test[['총자산대비잉여현금흐름', 'log자산총계', '순운전자본회전률', '총자본증가율', '자기자본구성비율', '총자본회전률',\n",
    "       '자기자본회전률', '자기자본증가율', '유동자산회전률', '총자산대비현금흐름', '총자본투자효율', '총자본순이익률']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('t-1감사의견코드',axis=1)\n",
    "y_train = train[['t-1감사의견코드']]\n",
    "\n",
    "X_test = test.drop('t-1감사의견코드',axis=1)\n",
    "y_test = test[['t-1감사의견코드']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    # Stratified 5-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    # 최적 하이퍼파라미터 설정 (여기서는 고정값으로 사용)\n",
    "    best_params = {'C': 0.07, 'penalty': 'l2'}\n",
    "\n",
    "    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    confusion_matrix_list = []\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # 로지스틱 회귀 모델 초기화\n",
    "        model = LogisticRegression(C=best_params['C'], penalty=best_params['penalty'], n_jobs=-1)\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # 테스트 데이터에 대한 예측\n",
    "        y_pred = model.predict(X_test_fold)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test_fold, y_pred)\n",
    "        precision = precision_score(y_test_fold, y_pred)\n",
    "        recall = recall_score(y_test_fold, y_pred)\n",
    "        f1 = f1_score(y_test_fold, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test_fold, y_pred)\n",
    "\n",
    "        # 각 fold 별 평가 지표를 리스트에 추가\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # 가장 좋은 f1-score 값을 가진 모델을 저장\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = model\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n",
    "    y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "    precision_final = precision_score(y_test, y_pred_final)\n",
    "    recall_final = recall_score(y_test, y_pred_final)\n",
    "    f1_final = f1_score(y_test, y_pred_final)\n",
    "    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "    print(\"Final Test Results\")\n",
    "    print(f\"Accuracy: {accuracy_final}\")\n",
    "    print(f\"Precision: {precision_final}\")\n",
    "    print(f\"Recall: {recall_final}\")\n",
    "    print(f\"F1 score: {f1_final}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_final)\n",
    "\n",
    "    return accuracy_final, precision_final, recall_final, f1_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Accuracy: 0.8361757105943153\n",
      "Precision: 0.7393538913362702\n",
      "Recall: 0.5244791666666667\n",
      "F1 score: 0.6136502132845826\n",
      "Confusion Matrix:\n",
      "[[5465  355]\n",
      " [ 913 1007]]\n",
      "------------------------------\n",
      "Fold 2\n",
      "Accuracy: 0.8301033591731266\n",
      "Precision: 0.7214912280701754\n",
      "Recall: 0.5137948984903696\n",
      "F1 score: 0.6001824262693828\n",
      "Confusion Matrix:\n",
      "[[5438  381]\n",
      " [ 934  987]]\n",
      "------------------------------\n",
      "Fold 3\n",
      "Accuracy: 0.8368217054263566\n",
      "Precision: 0.746996996996997\n",
      "Recall: 0.5179593961478397\n",
      "F1 score: 0.6117430064555794\n",
      "Confusion Matrix:\n",
      "[[5482  337]\n",
      " [ 926  995]]\n",
      "------------------------------\n",
      "Fold 4\n",
      "Accuracy: 0.839901796097687\n",
      "Precision: 0.7409766454352441\n",
      "Recall: 0.5453125\n",
      "F1 score: 0.6282628262826282\n",
      "Confusion Matrix:\n",
      "[[5453  366]\n",
      " [ 873 1047]]\n",
      "------------------------------\n",
      "Fold 5\n",
      "Accuracy: 0.832536503424215\n",
      "Precision: 0.7342342342342343\n",
      "Recall: 0.509375\n",
      "F1 score: 0.6014760147601476\n",
      "Confusion Matrix:\n",
      "[[5465  354]\n",
      " [ 942  978]]\n",
      "------------------------------\n",
      "Final Test Results\n",
      "Accuracy: 0.837082540231874\n",
      "Precision: 0.7481108312342569\n",
      "Recall: 0.5177824267782427\n",
      "F1 score: 0.6119925819080982\n",
      "Confusion Matrix:\n",
      "[[8190  500]\n",
      " [1383 1485]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.837082540231874, 0.7481108312342569, 0.5177824267782427, 0.6119925819080982)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_logistic_regression(X_train_int, y_train, X_test_int, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_random_forest(X_train, y_train, X_test, y_test):\n",
    "    # Stratified 5-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=0)\n",
    "\n",
    "    # 최적 하이퍼파라미터 설정 (여기서는 고정값으로 사용)\n",
    "    best_params = {'max_depth': 9, 'min_samples_leaf': 20, 'max_features':'auto', 'n_estimators':200}\n",
    "\n",
    "    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    confusion_matrix_list = []\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # 랜덤 포레스트 모델 초기화\n",
    "        model = RandomForestClassifier(max_depth=best_params['max_depth'],\n",
    "                                       min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                       n_estimators=best_params['n_estimators'],\n",
    "                                       max_features= best_params['max_features'],\n",
    "                                       random_state=0)\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # 테스트 데이터에 대한 예측 확률 얻기\n",
    "        probabilities = model.predict_proba(X_test_fold)\n",
    "\n",
    "        # threshold를 0.4로 설정하여 예측 클래스를 조정\n",
    "        threshold = 0.43\n",
    "        predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test_fold, predicted_classes)\n",
    "        precision = precision_score(y_test_fold, predicted_classes)\n",
    "        recall = recall_score(y_test_fold, predicted_classes)\n",
    "        f1 = f1_score(y_test_fold, predicted_classes)\n",
    "        conf_matrix = confusion_matrix(y_test_fold, predicted_classes)\n",
    "\n",
    "        # 각 fold 별 평가 지표를 리스트에 추가\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # 가장 좋은 f1-score 값을 가진 모델을 저장\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = model\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n",
    "    probabilities_final = best_model.predict_proba(X_test)\n",
    "    y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "    precision_final = precision_score(y_test, y_pred_final)\n",
    "    recall_final = recall_score(y_test, y_pred_final)\n",
    "    f1_final = f1_score(y_test, y_pred_final)\n",
    "    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "    print(\"Final Test Results\")\n",
    "    print(f\"Accuracy: {accuracy_final}\")\n",
    "    print(f\"Precision: {precision_final}\")\n",
    "    print(f\"Recall: {recall_final}\")\n",
    "    print(f\"F1 score: {f1_final}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_final)\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Accuracy: 0.8934707903780069\n",
      "Precision: 0.7758985200845666\n",
      "Recall: 0.8024781341107872\n",
      "F1 score: 0.7889645288427086\n",
      "Confusion Matrix:\n",
      "[[3839  318]\n",
      " [ 271 1101]]\n",
      "------------------------------\n",
      "Fold 2\n",
      "Accuracy: 0.8913004159884247\n",
      "Precision: 0.7675225537820958\n",
      "Recall: 0.8061224489795918\n",
      "F1 score: 0.7863490934944898\n",
      "Confusion Matrix:\n",
      "[[3822  335]\n",
      " [ 266 1106]]\n",
      "------------------------------\n",
      "Fold 3\n",
      "Accuracy: 0.8901953690303908\n",
      "Precision: 0.7776162790697675\n",
      "Recall: 0.7804522246535376\n",
      "F1 score: 0.779031670913724\n",
      "Confusion Matrix:\n",
      "[[3851  306]\n",
      " [ 301 1070]]\n",
      "------------------------------\n",
      "Fold 4\n",
      "Accuracy: 0.8925470332850941\n",
      "Precision: 0.7809110629067245\n",
      "Recall: 0.787746170678337\n",
      "F1 score: 0.7843137254901961\n",
      "Confusion Matrix:\n",
      "[[3854  303]\n",
      " [ 291 1080]]\n",
      "------------------------------\n",
      "Fold 5\n",
      "Accuracy: 0.8939942112879884\n",
      "Precision: 0.7688098495212038\n",
      "Recall: 0.8192419825072886\n",
      "F1 score: 0.7932251235003529\n",
      "Confusion Matrix:\n",
      "[[3818  338]\n",
      " [ 248 1124]]\n",
      "------------------------------\n",
      "Fold 6\n",
      "Accuracy: 0.8869392185238785\n",
      "Precision: 0.7588357588357588\n",
      "Recall: 0.7981049562682215\n",
      "F1 score: 0.77797513321492\n",
      "Confusion Matrix:\n",
      "[[3808  348]\n",
      " [ 277 1095]]\n",
      "------------------------------\n",
      "Fold 7\n",
      "Accuracy: 0.8880246020260492\n",
      "Precision: 0.7638402242466713\n",
      "Recall: 0.7944606413994169\n",
      "F1 score: 0.7788495891389782\n",
      "Confusion Matrix:\n",
      "[[3819  337]\n",
      " [ 282 1090]]\n",
      "------------------------------\n",
      "Final Test Results\n",
      "Accuracy: 0.8897733171829036\n",
      "Precision: 0.7733196159122085\n",
      "Recall: 0.7862622036262203\n",
      "F1 score: 0.7797372060857538\n",
      "Confusion Matrix:\n",
      "[[8029  661]\n",
      " [ 613 2255]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.8934707903780069,\n",
       "  0.8913004159884247,\n",
       "  0.8901953690303908,\n",
       "  0.8925470332850941,\n",
       "  0.8939942112879884,\n",
       "  0.8869392185238785,\n",
       "  0.8880246020260492],\n",
       " [0.7758985200845666,\n",
       "  0.7675225537820958,\n",
       "  0.7776162790697675,\n",
       "  0.7809110629067245,\n",
       "  0.7688098495212038,\n",
       "  0.7588357588357588,\n",
       "  0.7638402242466713],\n",
       " [0.8024781341107872,\n",
       "  0.8061224489795918,\n",
       "  0.7804522246535376,\n",
       "  0.787746170678337,\n",
       "  0.8192419825072886,\n",
       "  0.7981049562682215,\n",
       "  0.7944606413994169],\n",
       " [0.7889645288427086,\n",
       "  0.7863490934944898,\n",
       "  0.779031670913724,\n",
       "  0.7843137254901961,\n",
       "  0.7932251235003529,\n",
       "  0.77797513321492,\n",
       "  0.7788495891389782])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_random_forest(X_train_int, y_train, X_test_int, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_lgbm(X_train, y_train, X_test, y_test, k_fold=5):\n",
    "    # Stratified k-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n",
    "\n",
    "    # LGBM 하이퍼파라미터 설정 (여기서는 고정값으로 사용)\n",
    "    params = {\n",
    "        'max_depth': 20,\n",
    "        'min_child_samples': 10,\n",
    "        'n_estimators':180,\n",
    "        'learning_rate': 0.1,\n",
    "        'objective': 'binary',\n",
    "        'random_state': 0\n",
    "    }\n",
    "\n",
    "    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    confusion_matrix_list = []\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # LGBM 모델 초기화\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # 테스트 데이터에 대한 예측 확률 얻기\n",
    "        probabilities = model.predict_proba(X_test_fold)\n",
    "\n",
    "        # threshold를 0.4로 설정하여 예측 클래스를 조정\n",
    "        threshold = 0.5\n",
    "        predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test_fold, predicted_classes)\n",
    "        precision = precision_score(y_test_fold, predicted_classes)\n",
    "        recall = recall_score(y_test_fold, predicted_classes)\n",
    "        f1 = f1_score(y_test_fold, predicted_classes)\n",
    "        conf_matrix = confusion_matrix(y_test_fold, predicted_classes)\n",
    "\n",
    "        # 각 fold 별 평가 지표를 리스트에 추가\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # 가장 좋은 f1-score 값을 가진 모델을 저장\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = model\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n",
    "    probabilities_final = best_model.predict_proba(X_test)\n",
    "    y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "    precision_final = precision_score(y_test, y_pred_final)\n",
    "    recall_final = recall_score(y_test, y_pred_final)\n",
    "    f1_final = f1_score(y_test, y_pred_final)\n",
    "    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "    print(\"Final Test Results\")\n",
    "    print(f\"Accuracy: {accuracy_final}\")\n",
    "    print(f\"Precision: {precision_final}\")\n",
    "    print(f\"Recall: {recall_final}\")\n",
    "    print(f\"F1 score: {f1_final}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_final)\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Accuracy: 0.891343669250646\n",
      "Precision: 0.7972451790633609\n",
      "Recall: 0.7536458333333333\n",
      "F1 score: 0.7748326639892905\n",
      "Confusion Matrix:\n",
      "[[5452  368]\n",
      " [ 473 1447]]\n",
      "------------------------------\n",
      "Fold 2\n",
      "Accuracy: 0.8988372093023256\n",
      "Precision: 0.8105895196506551\n",
      "Recall: 0.7730348776678813\n",
      "F1 score: 0.7913669064748202\n",
      "Confusion Matrix:\n",
      "[[5472  347]\n",
      " [ 436 1485]]\n",
      "------------------------------\n",
      "Fold 3\n",
      "Accuracy: 0.8939276485788114\n",
      "Precision: 0.8042035398230089\n",
      "Recall: 0.7568974492451848\n",
      "F1 score: 0.7798337355859479\n",
      "Confusion Matrix:\n",
      "[[5465  354]\n",
      " [ 467 1454]]\n",
      "------------------------------\n",
      "Fold 4\n",
      "Accuracy: 0.8953353146401344\n",
      "Precision: 0.7942735949098622\n",
      "Recall: 0.7802083333333333\n",
      "F1 score: 0.7871781397792957\n",
      "Confusion Matrix:\n",
      "[[5431  388]\n",
      " [ 422 1498]]\n",
      "------------------------------\n",
      "Fold 5\n",
      "Accuracy: 0.8944308050135676\n",
      "Precision: 0.7992403689636463\n",
      "Recall: 0.7671875\n",
      "F1 score: 0.7828859952165825\n",
      "Confusion Matrix:\n",
      "[[5449  370]\n",
      " [ 447 1473]]\n",
      "------------------------------\n",
      "Final Test Results\n",
      "Accuracy: 0.8946184460979408\n",
      "Precision: 0.8080657206870799\n",
      "Recall: 0.7545327754532776\n",
      "F1 score: 0.7803822574828705\n",
      "Confusion Matrix:\n",
      "[[8176  514]\n",
      " [ 704 2164]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.891343669250646,\n",
       "  0.8988372093023256,\n",
       "  0.8939276485788114,\n",
       "  0.8953353146401344,\n",
       "  0.8944308050135676],\n",
       " [0.7972451790633609,\n",
       "  0.8105895196506551,\n",
       "  0.8042035398230089,\n",
       "  0.7942735949098622,\n",
       "  0.7992403689636463],\n",
       " [0.7536458333333333,\n",
       "  0.7730348776678813,\n",
       "  0.7568974492451848,\n",
       "  0.7802083333333333,\n",
       "  0.7671875],\n",
       " [0.7748326639892905,\n",
       "  0.7913669064748202,\n",
       "  0.7798337355859479,\n",
       "  0.7871781397792957,\n",
       "  0.7828859952165825])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_lgbm(X_train_int, y_train, X_test_int, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def perform_lgbm_grid_search(X_train, y_train, k_fold=5):\n",
    "    # Stratified k-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n",
    "\n",
    "    # LGBM 하이퍼파라미터 후보 리스트 설정\n",
    "    param_grid = {\n",
    "        'max_depth': [16],\n",
    "        'n_estimators': [220],\n",
    "        'learning_rate': [0.08],\n",
    "        'objective': ['binary'],\n",
    "        'random_state': [0],\n",
    "        'min_child_samples' :[20]\n",
    "    }\n",
    "\n",
    "    # LGBM 모델 초기화\n",
    "    model = lgb.LGBMClassifier()\n",
    "\n",
    "    # 그리드 서치 설정\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='recall', cv=cv, verbose=1, n_jobs=-1)\n",
    "\n",
    "    # 모델 학습 및 튜닝\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # 최적 하이퍼파라미터 출력\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "    # 평균 평가 지표 계산\n",
    "    mean_f1_score = np.mean(grid_search.cv_results_['mean_test_score'])\n",
    "    print(\"Mean F1 Score:\", mean_f1_score)\n",
    "\n",
    "    return grid_search.best_params_, mean_f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_lgbm_with_best_params(X_train, y_train, X_test, y_test, best_params, k_fold=5):\n",
    "    # Stratified k-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n",
    "\n",
    "    # LGBM 모델 초기화\n",
    "    model = lgb.LGBMClassifier(**best_params)\n",
    "\n",
    "    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    confusion_matrix_list = []\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # 테스트 데이터에 대한 예측 확률 얻기\n",
    "        probabilities = model.predict_proba(X_test_fold)\n",
    "\n",
    "        # threshold를 0.4로 설정하여 예측 클래스를 조정\n",
    "        threshold = 0.4\n",
    "        predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test_fold, predicted_classes)\n",
    "        precision = precision_score(y_test_fold, predicted_classes)\n",
    "        recall = recall_score(y_test_fold, predicted_classes)\n",
    "        f1 = f1_score(y_test_fold, predicted_classes)\n",
    "        conf_matrix = confusion_matrix(y_test_fold, predicted_classes)\n",
    "\n",
    "        # 각 fold 별 평가 지표를 리스트에 추가\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # 가장 좋은 f1-score 값을 가진 모델을 저장\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = model\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n",
    "    probabilities_final = best_model.predict_proba(X_test)\n",
    "    y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "    precision_final = precision_score(y_test, y_pred_final)\n",
    "    recall_final = recall_score(y_test, y_pred_final)\n",
    "    f1_final = f1_score(y_test, y_pred_final)\n",
    "    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "    print(\"Final Test Results\")\n",
    "    print(f\"Accuracy: {accuracy_final}\")\n",
    "    print(f\"Precision: {precision_final}\")\n",
    "    print(f\"Recall: {recall_final}\")\n",
    "    print(f\"F1 score: {f1_final}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_final)\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_score_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 1 candidates, totalling 7 fits\n",
      "Best Hyperparameters: {'learning_rate': 0.08, 'max_depth': 16, 'min_child_samples': 20, 'n_estimators': 220, 'objective': 'binary', 'random_state': 0}\n",
      "Mean F1 Score: 0.7611923794212903\n",
      "Fold 1\n",
      "Accuracy: 0.8947368421052632\n",
      "Precision: 0.7777777777777778\n",
      "Recall: 0.8061224489795918\n",
      "F1 score: 0.7916964924838941\n",
      "Confusion Matrix:\n",
      "[[3841  316]\n",
      " [ 266 1106]]\n",
      "------------------------------\n",
      "Fold 2\n",
      "Accuracy: 0.8903960933260987\n",
      "Precision: 0.7656033287101248\n",
      "Recall: 0.8046647230320699\n",
      "F1 score: 0.7846481876332622\n",
      "Confusion Matrix:\n",
      "[[3819  338]\n",
      " [ 268 1104]]\n",
      "------------------------------\n",
      "Fold 3\n",
      "Accuracy: 0.8914616497829233\n",
      "Precision: 0.7767408470926059\n",
      "Recall: 0.7892049598832969\n",
      "F1 score: 0.7829232995658467\n",
      "Confusion Matrix:\n",
      "[[3846  311]\n",
      " [ 289 1082]]\n",
      "------------------------------\n",
      "Fold 4\n",
      "Accuracy: 0.8974312590448625\n",
      "Precision: 0.7896253602305475\n",
      "Recall: 0.799416484318016\n",
      "F1 score: 0.794490757520841\n",
      "Confusion Matrix:\n",
      "[[3865  292]\n",
      " [ 275 1096]]\n",
      "------------------------------\n",
      "Fold 5\n",
      "Accuracy: 0.8959840810419681\n",
      "Precision: 0.7712729748127978\n",
      "Recall: 0.825801749271137\n",
      "F1 score: 0.7976064765927491\n",
      "Confusion Matrix:\n",
      "[[3820  336]\n",
      " [ 239 1133]]\n",
      "------------------------------\n",
      "Fold 6\n",
      "Accuracy: 0.8873010130246021\n",
      "Precision: 0.7559808612440191\n",
      "Recall: 0.8061224489795918\n",
      "F1 score: 0.7802469135802469\n",
      "Confusion Matrix:\n",
      "[[3799  357]\n",
      " [ 266 1106]]\n",
      "------------------------------\n",
      "Fold 7\n",
      "Accuracy: 0.8873010130246021\n",
      "Precision: 0.7617051013277428\n",
      "Recall: 0.7944606413994169\n",
      "F1 score: 0.7777381377095968\n",
      "Confusion Matrix:\n",
      "[[3815  341]\n",
      " [ 282 1090]]\n",
      "------------------------------\n",
      "Final Test Results\n",
      "Accuracy: 0.8936667243467727\n",
      "Precision: 0.7799795011957635\n",
      "Recall: 0.7960251046025104\n",
      "F1 score: 0.787920621225194\n",
      "Confusion Matrix:\n",
      "[[8046  644]\n",
      " [ 585 2283]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.8947368421052632,\n",
       "  0.8903960933260987,\n",
       "  0.8914616497829233,\n",
       "  0.8974312590448625,\n",
       "  0.8959840810419681,\n",
       "  0.8873010130246021,\n",
       "  0.8873010130246021],\n",
       " [0.7777777777777778,\n",
       "  0.7656033287101248,\n",
       "  0.7767408470926059,\n",
       "  0.7896253602305475,\n",
       "  0.7712729748127978,\n",
       "  0.7559808612440191,\n",
       "  0.7617051013277428],\n",
       " [0.8061224489795918,\n",
       "  0.8046647230320699,\n",
       "  0.7892049598832969,\n",
       "  0.799416484318016,\n",
       "  0.825801749271137,\n",
       "  0.8061224489795918,\n",
       "  0.7944606413994169],\n",
       " [0.7916964924838941,\n",
       "  0.7846481876332622,\n",
       "  0.7829232995658467,\n",
       "  0.794490757520841,\n",
       "  0.7976064765927491,\n",
       "  0.7802469135802469,\n",
       "  0.7777381377095968])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params, mean_f1_score = perform_lgbm_grid_search(X_train, y_train, k_fold=7)\n",
    "evaluate_lgbm_with_best_params(X_train_int, y_train, X_test_int, y_test, best_params, k_fold=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def perform_xgb_grid_search(X_train, y_train, k_fold=5):\n",
    "    # Stratified k-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n",
    "\n",
    "    # XGBoost 하이퍼파라미터 후보 리스트 설정\n",
    "    param_grid = {\n",
    "        'max_depth': [6, 8, 10],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'objective': ['binary:logistic'],\n",
    "        'random_state': [0],\n",
    "    }\n",
    "\n",
    "    # XGBoost 모델 초기화\n",
    "    model = xgb.XGBClassifier()\n",
    "\n",
    "    # 그리드 서치 설정\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=cv, verbose=1, n_jobs=-1)\n",
    "\n",
    "    # 모델 학습 및 튜닝\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # 최적 하이퍼파라미터 출력\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "    # 평균 평가 지표 계산\n",
    "    mean_f1_score = np.mean(grid_search.cv_results_['mean_test_score'])\n",
    "    print(\"Mean F1 Score:\", mean_f1_score)\n",
    "\n",
    "    return grid_search.best_params_, mean_f1_score\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_xgb_with_best_params(X_train, y_train, X_test, y_test, best_params, k_fold=5):\n",
    "    # Stratified k-fold 교차검증 설정\n",
    "    cv = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=0)\n",
    "\n",
    "    # XGBoost 모델 초기화\n",
    "    model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "    # 각 fold 별 평가 지표를 저장할 리스트 초기화\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_score_list = []\n",
    "    confusion_matrix_list = []\n",
    "\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train), 1):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_test_fold, y_test_fold = X_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # 테스트 데이터에 대한 예측 확률 얻기\n",
    "        probabilities = model.predict_proba(X_test_fold)\n",
    "\n",
    "        # threshold를 0.4로 설정하여 예측 클래스를 조정\n",
    "        threshold = 0.4\n",
    "        predicted_classes = (probabilities[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "        # 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test_fold, predicted_classes)\n",
    "        precision = precision_score(y_test_fold, predicted_classes)\n",
    "        recall = recall_score(y_test_fold, predicted_classes)\n",
    "        f1 = f1_score(y_test_fold, predicted_classes)\n",
    "        conf_matrix = confusion_matrix(y_test_fold, predicted_classes)\n",
    "\n",
    "        # 각 fold 별 평가 지표를 리스트에 추가\n",
    "        accuracy_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_score_list.append(f1)\n",
    "        confusion_matrix_list.append(conf_matrix)\n",
    "\n",
    "        print(f\"Fold {fold_idx}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "        print(f\"F1 score: {f1}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(conf_matrix)\n",
    "        print(\"------------------------------\")\n",
    "\n",
    "        # 가장 좋은 f1-score 값을 가진 모델을 저장\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = model\n",
    "\n",
    "    # 가장 좋은 f1-score 값을 가진 모델로 최종 예측 수행\n",
    "    probabilities_final = best_model.predict_proba(X_test)\n",
    "    y_pred_final = (probabilities_final[:, 1] > threshold).astype(np.int)\n",
    "\n",
    "    # 평가 지표 계산\n",
    "    accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "    precision_final = precision_score(y_test, y_pred_final)\n",
    "    recall_final = recall_score(y_test, y_pred_final)\n",
    "    f1_final = f1_score(y_test, y_pred_final)\n",
    "    conf_matrix_final = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "    print(\"Final Test Results\")\n",
    "    print(f\"Accuracy: {accuracy_final}\")\n",
    "    print(f\"Precision: {precision_final}\")\n",
    "    print(f\"Recall: {recall_final}\")\n",
    "    print(f\"F1 score: {f1_final}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix_final)\n",
    "\n",
    "    return accuracy_list, precision_list, recall_list, f1_score_list\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[179], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_params, mean_f1_score \u001b[39m=\u001b[39m perform_xgb_grid_search(X_train, y_train, k_fold\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m evaluate_xgb_with_best_params(X_train_int, y_train, X_test_int, y_test, best_params, k_fold\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m)\n",
      "Cell \u001b[1;32mIn[178], line 25\u001b[0m, in \u001b[0;36mperform_xgb_grid_search\u001b[1;34m(X_train, y_train, k_fold)\u001b[0m\n\u001b[0;32m     22\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(model, param_grid, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m, cv\u001b[39m=\u001b[39mcv, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[39m# 모델 학습 및 튜닝\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     27\u001b[0m \u001b[39m# 최적 하이퍼파라미터 출력\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Hyperparameters:\u001b[39m\u001b[39m\"\u001b[39m, grid_search\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\dgh06\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_params, mean_f1_score = perform_xgb_grid_search(X_train, y_train, k_fold=5)\n",
    "evaluate_xgb_with_best_params(X_train_int, y_train, X_test_int, y_test, best_params, k_fold=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
